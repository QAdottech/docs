---
title: AI Agent Testing
description: 'An intro to AI agents, and how they are used for QA'
icon: user-secret
---

AI agents are autonomous software entities that perform tasks or make decisions based on input data, using artificial intelligence techniques. They can learn, adapt, and operate without constant human intervention.

They can handle complex tasks in various domains by learning from their experiences. For example: AI agents can serve as virtual assistants, help power autonomous vehicles, and support recommendation systems

## What is AI agent testing

It’s testing, but using AI agents instead of humans or scripts to complete the tasks.

**What are the benefits of AI agent testing?**

**Flexibility**

AI agents can handle more open-ended instructions compared to a traditional script-based automation tool. An agent can take an instruction such as “fill out a form with values that make sense”, and produce great results while using a script or automation tool would require complex setups for each field you want to fill in.

**More human-like behavior**

Agents can be primed to use different approaches every time – making them perfect for testing systems with multiple permutations of a user flow.

For example: Testing an e-commerce application, the agent could add a different mix of items to the cart each time, and check out with different addresses, behaving much more like a normal end user – making it great at finding bugs in edge cases

**Fast**

While not as fast as optimized code (….yet), AI agents are able to operate faster than their human counterparts. Being available 24/7 and never getting bored, they excel at being thorough even for highly repetitive testing tasks.

**What are AI agents bad at**

**Very deterministic tests**

Do you have a large set of actions that need to be done in the exact same order, every time? Then scripted tests are great. Use AI agent testing to test the less predictable user flows, as a complement to the scripted user journeys.

**Math**
If you need to do complex calculations and financial operations, stick with deterministic calculations in code! AI can sanity check things but does not have good mathematical skills at this time.

**Tests that require privileged access**

If your test relies on changing state in a database, an API, or something else not accessible through the web, you need to do a specific setup for that.

## How QA.tech uses specialized agents

QA.tech routes testing tasks to different specialized agents based on context. You don't manage these directly—they activate automatically based on what you're trying to accomplish.

**Interactive Testing: [Chat Assistant](/core-concepts/ai-chat-assistant)**

Handles conversational workflows where you need to iterate on test coverage, ask questions about your application, or generate test cases. The chat agent coordinates with other specialists (test generation, explorative testing, onboarding) depending on your request.

Use this when: You're actively exploring what to test, generating new test cases, or need help understanding QA.tech features.

**Autonomous PR Testing: [GitHub App](/configuration/github-app)**

Automatically reviews pull requests by analyzing code changes, determining what user-facing functionality changed, generating relevant tests, executing them, and posting detailed reviews. Operates fully autonomously—no human interaction required or possible during execution.

Use this when: You want every PR automatically tested before merge, without manual intervention.

**On-Demand PR Testing: [GitHub Actions](/configuration/github-exploratory-testing)**

Triggered by mentioning `@qatech` in a PR comment. Runs explorative testing against your preview environment and posts findings. Similar to the autonomous agent but human-initiated.

Use this when: You want control over when exploratory testing runs, or you're evaluating QA.tech in a private beta.

**First-Time Setup: Onboarding Agent**

Guides new projects through initial crawling, login setup, and creation of 3-5 high-impact test cases (prioritizing revenue-critical flows like checkout and payments). Accessed through the [Chat Assistant](/core-concepts/ai-chat-assistant) during project setup.

Use this when: You're setting up QA.tech for the first time and need to establish baseline test coverage quickly.

## Choosing the right approach

| Scenario | AI Agents | Scripts | Manual QA |
|:---------|:----------|:--------|:----------|
| **Exploratory testing** | ✅ Best - can discover edge cases through varied behavior | ❌ Fixed paths only | ✅ Good - but slow and expensive |
| **Regression testing** | ✅ Good - handles UI changes gracefully | ✅ Best - fastest execution | ❌ Too repetitive |
| **Exact same steps every time** | ⚠️ Possible but overkill | ✅ Best - fully deterministic | ❌ Error-prone over time |
| **Testing multiple user flows** | ✅ Best - tries different approaches automatically | ⚠️ Need separate script per variant | ✅ Good - but doesn't scale |
| **Complex calculations** | ❌ Use assertions in code instead | ✅ Best - precise math | ⚠️ Manual calculation prone to errors |
| **Form filling with realistic data** | ✅ Best - understands context | ⚠️ Need hardcoded test data | ✅ Good - but tedious |
| **Testing preview environments** | ✅ Best - [automatic PR reviews](/configuration/github-app) | ⚠️ Need CI/CD integration | ❌ Requires manual coordination |
| **First-time test coverage** | ✅ Best - [onboarding agent](/core-concepts/ai-chat-assistant) sets up quickly | ❌ Requires upfront investment | ⚠️ Slow to establish baseline |

In practice, most teams use a combination: AI agents for exploration and edge cases, scripts for critical deterministic flows, and manual QA for subjective evaluation (design, UX, brand consistency).
