---
title: Welcome to QA.tech
description: 'Autonomous AI testing'
icon: home
---

QA.tech uses specialized AI agents to test your application like humans would, but faster and more thoroughly. Our system automatically routes testing tasks to the right agent based on context-no manual configuration needed.

## Our AI Agent System

| Agent | Purpose | How It Activates | Learn More |
|:------|:--------|:-----------------|:-----------|
| **Chat Assistant** | Interactive testing, test creation, project analysis | You start a conversation | [AI Chat Assistant](/core-concepts/ai-chat-assistant) |
| **PR Review** | Autonomous testing of every pull request | Automatic on PR open/update | [GitHub App](/configuration/github-app) |
| **Explorative** | Deep on-demand testing with custom instructions | `@qatech` mention in PR comments | [GitHub Actions](/configuration/github-actions) |
| **Test Generation** | Creates test cases from requirements | Via Chat Assistant | [AI Chat Assistant](/core-concepts/ai-chat-assistant) |
| **Onboarding** | First-time setup and baseline test coverage | Via Chat Assistant | [AI Chat Assistant](/core-concepts/ai-chat-assistant) |

## How It Works in Practice

Here's what happens when you open a PR that changes your checkout flow:

**1. Automatic Detection**
```
PR opened: "Add Apple Pay to checkout"
→ PR Review agent activates
```

**2. Change Classification**
```
Analyzing diff...
├─ checkout.tsx: USER-FACING ✓
├─ payment-methods.ts: USER-FACING ✓
└─ README.md: DOCS ONLY ✗

Classification: USER-FACING changes detected
```

**3. Coverage Assessment**
```
Existing tests found:
├─ "Complete checkout with credit card" ✓
├─ "Complete checkout with PayPal" ✓
└─ Apple Pay integration: NOT COVERED ⚠️
```

**4. Test Generation**
```
Creating new test:
"Complete checkout flow with Apple Pay"
├─ Add item to cart
├─ Navigate to checkout
├─ Select Apple Pay as payment method
├─ Verify payment confirmation
└─ Verify order appears in account
```

**5. Execution & Review**
```
Running against PR preview environment...
✅ All tests passing (3/3)

Posting GitHub review:
"✅ Tests passing - Apple Pay integration verified"
```

This entire workflow runs autonomously - no human intervention required.

## When to Use AI Agents vs Scripts

| Scenario | AI Agents | Scripts | Manual QA |
|:---------|:----------|:--------|:----------|
| **Exploratory testing** | ✅ Best - discovers edge cases through varied behavior | ❌ Fixed paths only | ✅ Good - but slow and expensive |
| **Regression testing** | ✅ Good - handles UI changes gracefully | ✅ Best - fastest execution | ❌ Too repetitive |
| **Exact same steps every time** | ⚠️ Possible but overkill | ✅ Best - fully deterministic | ❌ Error-prone over time |
| **Testing multiple user flows** | ✅ Best - tries different approaches automatically | ⚠️ Need separate script per variant | ✅ Good - but doesn't scale |
| **Complex calculations** | ❌ Use assertions in code instead | ✅ Best - precise math | ⚠️ Manual calculation prone to errors |
| **Form filling with realistic data** | ✅ Best - understands context | ⚠️ Need hardcoded test data | ✅ Good - but tedious |
| **Testing preview environments** | ✅ Best - [automatic PR reviews](/configuration/github-app) | ⚠️ Need CI/CD integration | ❌ Requires manual coordination |
| **First-time test coverage** | ✅ Best - [onboarding agent](/core-concepts/ai-chat-assistant) sets up quickly | ❌ Requires upfront investment | ⚠️ Slow to establish baseline |

In practice, most teams use a combination: AI agents for exploration and edge cases, scripts for critical deterministic flows, and manual QA for subjective evaluation (design, UX, brand consistency).

## Agent Coordination

Agents automatically hand off tasks to specialists when needed:

**Chat → Test Generation**
```
You: "Create 5 tests for the checkout flow"
→ Chat Assistant routes to Test Generation agent
→ Analyzes your application structure
→ Creates tests prioritizing revenue-critical paths
```

**Chat → Explorative**
```
You: "Test this pull request"
→ Chat Assistant routes to Explorative agent
→ Fetches PR details and preview environment
→ Runs tests and posts review
```

**PR Review → Test Generation**
```
PR detected with untested functionality
→ PR Review agent requests new tests
→ Test Generation creates coverage
→ PR Review executes and reports
```

You don't manage this coordination - it happens automatically based on what you're trying to accomplish.

## Test Execution Model

QA.tech uses Claude Haiku 4.5 as the default AI model for test execution. This model provides the fastest test execution while maintaining high-quality results.

| Model | Speed | Best For |
|:------|:------|:---------|
| **Claude Haiku 4.5** (default) | Fastest | Most tests - recommended for day-to-day testing |
| Claude Sonnet 4.5 | Moderate | Complex scenarios requiring deeper reasoning |

The AI model handles all test execution decisions: navigating your application, filling forms, clicking buttons, and verifying outcomes. You write test goals in natural language, and the model figures out how to achieve them.

<Note>
You can override the agent per-test in the Advanced settings when creating or editing a test. See [Creating Tests](/best-practices/creating-tests#choosing-an-ai-agent) for details.
</Note>

## Get Started

<CardGroup cols={2}>
  <Card title="Create Your First Test" icon="plus" href="/best-practices/creating-tests">
    Write tests in natural language. The AI generates steps automatically.
  </Card>
  <Card title="AI Chat Assistant" icon="message-bot" href="/core-concepts/ai-chat-assistant">
    Conversational interface to create, edit, and manage tests.
  </Card>
  <Card title="Automatic PR Testing" icon="github" href="/configuration/github-app">
    Install the GitHub App for autonomous reviews on every PR.
  </Card>
  <Card title="CI/CD Integration" icon="code" href="/configuration/ci-cd-integration">
    Trigger tests from your deployment pipeline.
  </Card>
</CardGroup>
