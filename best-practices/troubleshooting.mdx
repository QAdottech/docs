---
title: Troubleshooting
description: 'Comprehensive guide to resolving common QA.tech issues, AI test failures, and configuration problems'
icon: triangle-exclamation
---

# Troubleshooting Guide

This comprehensive troubleshooting guide helps you resolve common issues with QA.tech's AI-powered testing platform. Learn how to interpret AI-generated results, optimize prompts, and handle test failures effectively.

## Quick Diagnosis

### Common Issues Checklist

Before diving into specific problems, check these common causes:

- [ ] **API Token**: Valid and properly configured in app.qa.tech
- [ ] **Project Access**: You have access to the project
- [ ] **Application URL**: Target application is accessible and working
- [ ] **Test Plan**: Test plan exists and is properly configured
- [ ] **AI Agent**: AI agent can access your application
- [ ] **Network**: Internet connection to app.qa.tech
- [ ] **Permissions**: Proper access rights to run tests

## Understanding AI Test Results

### Interpreting "7 Passed / 1 Failed"

**Problem:** You see results like "7 Passed / 1 Failed" and don't understand what this means.

**Explanation:**
- **Passed Steps**: AI successfully completed 7 individual actions
- **Failed Steps**: AI encountered 1 issue during test execution
- **Total Steps**: The AI agent broke down your test into 8 total steps

**Solutions:**

<Steps>
  <Step title="Review the Detailed Results">
    Click on the test result to see:
    - Which specific step failed
    - What the AI was trying to do
    - Screenshots of the failure point
    - Console logs and error messages
  </Step>
  <Step title="Understand AI Decision Making">
    The AI agent makes decisions based on:
    - Page content and structure
    - Available interactive elements
    - Your test description
    - Previous successful patterns
  </Step>
  <Step title="Check Application State">
    Verify your application:
    - Is the page loading correctly?
    - Are all elements visible and accessible?
    - Is the application behaving as expected?
    - Are there any popups or overlays?
  </Step>
</Steps>

### AI Agent Can't Find Elements

**Problem:** AI agent reports "element not found" or "cannot interact with element."

**Solutions:**

<Steps>
  <Step title="Improve Your Test Description">
    Write clearer, more specific instructions:
    - Use specific element names and descriptions
    - Include context about where to find elements
    - Specify the exact action to perform
    - Add step-by-step navigation guidance
  </Step>
  <Step title="Check Application Accessibility">
    Ensure your application is AI-friendly:
    - Add descriptive text to buttons and links
    - Use semantic HTML elements
    - Provide clear labels for form fields
    - Avoid generic text like "Click here"
  </Step>
  <Step title="Verify Element Visibility">
    Check that elements are:
    - Visible on the page
    - Not hidden by CSS
    - Not covered by overlays
    - In the viewport
  </Step>
  <Step title="Use the AI Chat Feature">
    Ask the AI directly:
    - "Why can't you find the login button?"
    - "What elements do you see on this page?"
    - "How should I describe this element better?"
  </Step>
</Steps>

**Example Better Test Description:**
```
Instead of: "Test the login form"
Use: "Test the login form by entering email 'test@example.com' in the email field, entering password 'password123' in the password field, and clicking the 'Sign In' button"
```

## Prompt Optimization Issues

### AI Generates Wrong Tests

**Problem:** The AI creates tests that don't match your requirements.

**Solutions:**

<Steps>
  <Step title="Be More Specific in Prompts">
    Provide detailed context:
    - Describe the exact user journey
    - Specify the business logic to test
    - Include expected outcomes
    - Mention important validation points
  </Step>
  <Step title="Use the Chat Interface">
    Have a conversation with the AI:
    - "I want to test the checkout process"
    - "Focus on the payment validation"
    - "Make sure to verify the order confirmation"
  </Step>
  <Step title="Review and Edit Generated Tests">
    After AI generates a test:
    - Review the test steps
    - Edit any incorrect assumptions
    - Add missing validations
    - Adjust the test flow
  </Step>
  <Step title="Provide Better Context">
    Help the AI understand your application:
    - Describe the user personas
    - Explain the business workflow
    - Mention critical paths
    - Specify edge cases to test
  </Step>
</Steps>

### Tests Are Too Generic

**Problem:** AI generates basic tests that don't cover your specific business logic.

**Solutions:**

<Steps>
  <Step title="Include Business Requirements">
    Add specific business context:
    - "Test that only valid email formats are accepted"
    - "Verify that users cannot checkout without a shipping address"
    - "Ensure that discount codes are properly applied"
  </Step>
  <Step title="Specify Validation Points">
    Tell the AI what to verify:
    - "Check that the total price is calculated correctly"
    - "Verify that error messages appear for invalid inputs"
    - "Ensure that successful actions show confirmation messages"
  </Step>
  <Step title="Use Bug Reproduction Prompts">
    For specific issues:
    - "Reproduce the bug where users can't reset their password"
    - "Test the scenario where the cart becomes empty unexpectedly"
    - "Verify the fix for the login timeout issue"
  </Step>
</Steps>

## Configuration Problems

### Project Setup Issues

**Problem:** Can't create or access projects in app.qa.tech.

**Solutions:**

<Steps>
  <Step title="Check Account Access">
    Verify your account:
    - Log in to app.qa.tech
    - Check your subscription plan
    - Verify project permissions
    - Contact support if access is denied
  </Step>
  <Step title="Create Project Properly">
    Set up a new project:
    - Click "Create a project"
    - Enter a descriptive project name
    - Add your application URL
    - Configure initial settings
  </Step>
  <Step title="Configure Applications">
    Set up your applications:
    - Add your application URL
    - Configure environment settings
    - Set up authentication if needed
    - Test the connection
  </Step>
</Steps>

### API Integration Issues

**Problem:** GitHub Actions or other integrations aren't working.

**Solutions:**

<Steps>
  <Step title="Verify API Token">
    Check your API configuration:
    - Generate a new API token in app.qa.tech
    - Add token to GitHub Secrets
    - Verify token has correct permissions
    - Test token with API calls
  </Step>
  <Step title="Check Project ID">
    Verify project configuration:
    - Get correct project ID from app.qa.tech
    - Update GitHub Action configuration
    - Test project ID with API
    - Verify project is accessible
  </Step>
  <Step title="Configure Test Plan">
    Set up test plan integration:
    - Create test plan in app.qa.tech
    - Get test plan short ID
    - Add to GitHub Action configuration
    - Test the integration
  </Step>
</Steps>

**GitHub Action Configuration Example:**
```yaml
- uses: QAdottech/run-action@v2
  with:
    project_id: 'your-project-id'
    api_token: ${{ secrets.QATECH_API_TOKEN }}
    test_plan_short_id: 'jgbinp'
```

## Performance and Reliability Issues

### Slow Test Execution

**Problem:** Tests take too long to complete.

**Solutions:**

<Steps>
  <Step title="Optimize Test Descriptions">
    Write more efficient prompts:
    - Focus on critical user paths
    - Remove unnecessary steps
    - Be specific about what to test
    - Avoid redundant validations
  </Step>
  <Step title="Check Application Performance">
    Verify your application:
    - Test page load times manually
    - Optimize slow-loading elements
    - Check for performance bottlenecks
    - Monitor application response times
  </Step>
  <Step title="Use Parallel Execution">
    Configure concurrent testing:
    - Set up multiple test plans
    - Use different test scenarios
    - Configure parallel execution
    - Monitor resource usage
  </Step>
</Steps>

### Flaky Test Results

**Problem:** Tests pass and fail inconsistently.

**Solutions:**

<Steps>
  <Step title="Improve Test Stability">
    Write more reliable tests:
    - Be specific about element identification
    - Include proper wait conditions
    - Handle dynamic content
    - Account for application state
  </Step>
  <Step title="Check Application Consistency">
    Ensure stable application:
    - Test application manually
    - Check for random elements
    - Verify consistent behavior
    - Monitor application changes
  </Step>
  <Step title="Use Retry Logic">
    Configure automatic retries:
    - Set up retry attempts
    - Configure retry intervals
    - Handle transient failures
    - Monitor retry patterns
  </Step>
</Steps>

## Debugging Techniques

### Understanding AI Test Execution

**Learn how the AI agent works:**

<Steps>
  <Step title="Review Test Execution Logs">
    Analyze detailed execution:
    - Check what the AI was trying to do
    - Review element selection decisions
    - Understand failure points
    - Analyze timing information
  </Step>
  <Step title="Use Screenshots and Videos">
    Visual debugging:
    - Review screenshots at failure points
    - Watch test execution videos
    - Compare with expected behavior
    - Identify visual issues
  </Step>
  <Step title="Check Console Logs">
    Review application logs:
    - Check for JavaScript errors
    - Monitor network requests
    - Verify data flow
    - Debug client-side issues
  </Step>
</Steps>

### Chat with AI for Debugging

**Use the AI chat feature for troubleshooting:**

<Steps>
  <Step title="Ask AI About Failures">
    Get AI insights:
    - "Why did this test fail?"
    - "What was the AI trying to do?"
    - "How can I fix this issue?"
    - "What should I check?"
  </Step>
  <Step title="Get Debugging Suggestions">
    Ask for help:
    - "What elements do you see on this page?"
    - "How should I describe this better?"
    - "What might be causing this issue?"
    - "Can you suggest a different approach?"
  </Step>
  <Step title="Improve Test Descriptions">
    Refine your prompts:
    - "How can I make this test more reliable?"
    - "What additional context should I provide?"
    - "How can I be more specific?"
    - "What am I missing?"
  </Step>
</Steps>

## Getting Help

### Before Contacting Support

**Gather necessary information:**

<Steps>
  <Step title="Collect Test Details">
    Document the issue:
    - Screenshot of test results
    - Test description and prompt used
    - Application URL and state
    - Steps to reproduce the issue
  </Step>
  <Step title="Check Application Status">
    Verify your application:
    - Test manually in browser
    - Check for recent changes
    - Verify application is working
    - Test with different browsers
  </Step>
  <Step title="Review AI Suggestions">
    Check AI recommendations:
    - Look at AI-generated suggestions
    - Review chat conversations
    - Check for improvement tips
    - Follow AI guidance
  </Step>
</Steps>

### Contact Information

**Get help from the QA.tech support team:**

- **Email Support**: hi@qa.tech
- **Documentation**: This troubleshooting guide
- **Community**: [Discord Server](https://discord.com/invite/SuMAkMpwYv)
- **Status Page**: Check system status for known issues

### Common Error Messages

| Error Message | Description | Solution |
|---------------|-------------|----------|
| `Element not found` | AI can't locate an element | Improve element description or check visibility |
| `Test execution failed` | General test failure | Check application state and test description |
| `Authentication failed` | Login issues | Verify credentials and login flow |
| `Network timeout` | Connection problems | Check internet connection and application accessibility |
| `Invalid test plan` | Test plan configuration issue | Verify test plan exists and is properly configured |

## Prevention Best Practices

### Regular Maintenance

**Implement ongoing maintenance:**

<Steps>
  <Step title="Update Test Descriptions">
    Keep tests current:
    - Review and update test prompts
    - Remove obsolete tests
    - Improve test descriptions
    - Add new test scenarios
  </Step>
  <Step title="Monitor Test Performance">
    Track test health:
    - Monitor success rates
    - Track execution times
    - Analyze failure patterns
    - Identify improvement opportunities
  </Step>
  <Step title="Stay Updated">
    Keep current:
    - Check for QA.tech updates
    - Review new features
    - Update test strategies
    - Learn new capabilities
  </Step>
</Steps>

### Documentation

**Maintain comprehensive documentation:**

<Steps>
  <Step title="Document Test Strategies">
    Keep test documentation current:
    - Document test creation approaches
    - Record successful prompt patterns
    - Maintain troubleshooting guides
    - Share lessons learned
  </Step>
  <Step title="Create Team Guidelines">
    Develop team procedures:
    - Standardize test creation process
    - Create prompt templates
    - Document best practices
    - Share knowledge with team
  </Step>
</Steps>

## Advanced Troubleshooting

### Enterprise Scenarios

**Handle complex enterprise environments:**

#### **Multi-Environment Testing**
- Configure different applications for dev/staging/prod
- Set up environment-specific test plans
- Manage different authentication methods
- Implement environment validation

#### **Corporate Network Issues**
- Configure proxy settings if required
- Handle VPN requirements
- Manage firewall and security policies
- Test with corporate network restrictions

#### **Large-Scale Test Execution**
- Implement test plan organization strategies
- Manage test execution scheduling
- Monitor resource usage
- Optimize for enterprise needs

### Performance Optimization

**Optimize for high-performance testing:**

#### **Test Execution Optimization**
- Write efficient test descriptions
- Focus on critical user paths
- Remove unnecessary test steps
- Optimize test plan organization

#### **Application Performance**
- Monitor application response times
- Optimize slow-loading pages
- Implement proper caching
- Monitor application performance

## Conclusion

Effective troubleshooting with QA.tech requires understanding how the AI agent works and how to communicate effectively with it. By following this guide and implementing the best practices, you can:

- **Resolve issues quickly and efficiently**
- **Optimize AI test generation**
- **Maintain stable and reliable test execution**
- **Continuously improve your testing processes**

Remember to document solutions and share knowledge with your team to build collective troubleshooting expertise.

## Next Steps

- **[Creating Tests](/best-practices/creating-tests)** - Learn how to write effective AI prompts
- **[Project Context](/best-practices/project-context)** - Help AI understand your application
- **[Configuration](/configuration/github)** - Set up integrations and environments
- **[Test Results](/best-practices/test-results)** - Analyze AI-generated results
